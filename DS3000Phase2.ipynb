{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35935a5c-af0e-4781-9ae6-808ce1c99b44",
   "metadata": {},
   "source": [
    "# Phase II: Data Curation, Exploratory Analysis and Plotting (5\\%)\n",
    "\n",
    "### Team Members:\n",
    "- Logan Lary\n",
    "- Mark Tran\n",
    "- Sabrina Valerjev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c048d52-5297-4694-a9a4-5134bf78fba1",
   "metadata": {},
   "source": [
    "## Part 1: \n",
    "(1%) Expresses the central motivation of the project and explains the (at least) two key questions to be explored. Gives a summary of the data processing pipeline so a technical expert can easily follow along."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b496568b-b26e-439b-8490-b9b92e4d1dab",
   "metadata": {},
   "source": [
    "## Project Motivation \n",
    "The motivation for this project comes from our passion for movies and our curiosity about the factors that make them successful. As avid movie watchers, we are keen to explore the metadata behind films to uncover insights that intrigue us and hopefully resonate with others as well. This project aims to investigate the elements influencing both a movie's financial and critical success, such as cast, director, genre, release timing, studio, plot, and awards. By analyzing how these factors interact over time, we plan to create a predictive model that can estimate box office performance, forecast award nominations, and predict audience ratings. The key questions we seek to answer include: What factors have the most significant impact on a movieâ€™s success? How do these factors evolve, and how can they be used to predict future outcomes? This research will uncover trends in popular genres and success patterns, offering valuable insights for investors and helping to guide movie recommendations based on predicted success."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b1f408-fa48-4b88-9f8d-3a0acc3176e9",
   "metadata": {},
   "source": [
    "## Summary of the Data Processing Pipeline\n",
    "1. Web scrape from Box Office Mojo\n",
    "2. Create list of movies per year\n",
    "3. Use OMDb to access movie metadata each movie in the list\n",
    "4. Merge all the data into a single dataframe\n",
    "5. Clean the data\n",
    "\n",
    "The first step in our data processing pipeline was to scrape all box office mojo data. For this step, we referrenced and modified exisiting code written and published by Justin Mitchel on GitHub. This code provided the base for understanding the intricate setup of Box Office Mojo. The code was modified to work on any valid inputted year. The data from Box Office Mojo provided us a list with all of the movies from each year. We isolated this list of movie titles and fed them into OMDb to collect the metadata on each film. The last step in data collection was to merge the data on the shared \"Title\" attribute. This ensures that the financial information and movie information both reference the correct film. One difficulty in this data collection process was the limited amount of calls we could make to OMDb per day. To get around this limitation, we only requested data for certain years each day, and merged the resulting dataframes to get the entire collection of data. The data cleaning of this dataframe was simple. We decided to simplify the financial data by removing the commas and dollars sign from the numbers and converting the sums from dollars to millions of dollars to make future math calculations more simple. We also dropped columns that we determined to be not needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da990590-da74-45a0-b145-a2ed093ef27d",
   "metadata": {},
   "source": [
    "## Part 2: \n",
    "(2\\%) Obtains, cleans, and merges all data sources involved in the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27158c4c-68f4-450a-af25-e0872d72041b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding relevant imports\n",
    "import requests\n",
    "from requests_html import HTML\n",
    "import json\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import requests\n",
    "from requests_html import HTML\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4e939c3-1542-4f20-b4fb-0854bf130785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source 1: Box Office Mojo\n",
    "@dataclass\n",
    "class ScrapeBoxOffice:\n",
    "    base_endpoint:str = \"https://www.boxofficemojo.com/year/world/\"\n",
    "    year:int = None\n",
    "    save_raw:bool = False\n",
    "    save:bool = False\n",
    "    output_dir: str = \".\"\n",
    "    table_selector: str = '.imdb-scroll-table'\n",
    "    table_data = []\n",
    "    table_header_names = []\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    @property\n",
    "    def name(self):\n",
    "        return self.year if isinstance(self.year, int) else 'world'\n",
    "    \n",
    "    def get_endpoint(self):\n",
    "        endpoint = self.base_endpoint\n",
    "        if isinstance(self.year, int):\n",
    "            endpoint = f\"{endpoint}{self.year}/\"\n",
    "        return endpoint\n",
    "    \n",
    "    def get_output_dir(self):\n",
    "        return pathlib.Path(self.output_dir)\n",
    "    \n",
    "    def extract_html_str(self, endpoint=None):\n",
    "        url = endpoint if endpoint is not None else self.get_endpoint()\n",
    "        r = requests.get(url, stream=True)\n",
    "        html_text = None\n",
    "        status = r.status_code\n",
    "        if r.status_code == 200:\n",
    "            html_text = r.text\n",
    "            if self.save_raw:\n",
    "                output_fname = f\"{self.name}.html\"\n",
    "                raw_output_dir = self.get_output_dir() / 'html'\n",
    "                raw_output_dir.mkdir(exist_ok=True, parents=True)\n",
    "                output_fname = raw_output_dir / output_fname\n",
    "                with open(f\"{output_fname}\", 'w') as f:\n",
    "                    f.write(html_text)\n",
    "            return html_text, status\n",
    "        return html_text, status\n",
    "    \n",
    "    def parse_html(self, html_str=''):\n",
    "        r_html = HTML(html=html_str)\n",
    "        r_table = r_html.find(self.table_selector)\n",
    "        if len(r_table) == 0:\n",
    "            return None\n",
    "        table_data = []\n",
    "        header_names = []\n",
    "        parsed_table = r_table[0]\n",
    "        rows = parsed_table.find(\"tr\")\n",
    "        header_row = rows[0]\n",
    "        header_cols = header_row.find('th')\n",
    "        header_names = [x.text for x in header_cols]\n",
    "        for row in rows[1:]:\n",
    "            cols = row.find(\"td\")\n",
    "            row_data = []\n",
    "            row_dict_data = {}\n",
    "            for i, col in enumerate(cols):\n",
    "                header_name = header_names[i]\n",
    "                row_data.append(col.text)\n",
    "            table_data.append(row_data)\n",
    "        self.table_data = table_data\n",
    "        self.table_header_names = header_names\n",
    "        return self.table_data, self.table_header_names\n",
    "    \n",
    "    def to_df(self, data=[], columns=[]):\n",
    "        return pd.DataFrame(data, columns=columns)\n",
    "    \n",
    "    def run(self, save=False):\n",
    "        save = self.save if save is False else save\n",
    "        endpoint = self.get_endpoint()\n",
    "        html_str, status = self.extract_html_str(endpoint=endpoint)\n",
    "        if status not in range(200, 299):\n",
    "            raise Exception(f\"Extraction failed, endpoint status {status} at {endpoint}\")\n",
    "        data, headers = self.parse_html(html_str if html_str is not None else '')\n",
    "        df = self.to_df(data=data, columns=headers)\n",
    "        self.df = df\n",
    "        if save:\n",
    "            filepath = self.get_output_dir() / f'{self.name}.csv'\n",
    "            df.to_csv(filepath, index=False)\n",
    "        return self.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db54ad64-51c1-424f-a23d-073a58994715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source 2: OMDb\n",
    "API_KEY = \"f3eb77a3\"\n",
    "URL = \"http://www.omdbapi.com/?t=\"\n",
    "\n",
    "def get_movie_data(url, movie):\n",
    "    ''' Takes in the name of a movie and returns associated data on the movie.'''\n",
    "    movie_link = process_movie_name(movie)\n",
    "    complete_url = url + movie_link + \"&apikey=\" + API_KEY\n",
    "    response = requests.get(complete_url) \n",
    "    return response.json()\n",
    "\n",
    "def process_movie_name(movie):\n",
    "    ''' Takes in the name of a movie and modifies it so that it can be used in API call.'''\n",
    "    words = movie.split()\n",
    "    return '+'.join(words)\n",
    "\n",
    "# get the list of all movies in a year\n",
    "# get data on all those movies\n",
    "# save to a json\n",
    "def get_year_movie_data(movie_titles, url, year):\n",
    "    empty_data = {}\n",
    "    data_list = []\n",
    "    for movie in movie_titles:\n",
    "        response = get_movie_data(url, movie)\n",
    "        data_list.append(response)\n",
    "    with open(\"MovieData\" + year + \".json\", 'w') as json_file:\n",
    "        json.dump(data_list, json_file, indent=4) \n",
    "\n",
    "year = 2010\n",
    "dataframe_1 = pd.DataFrame()\n",
    "# we can only download ~ 3 years of data at one time\n",
    "# only run each while loop once, to download all the data and prevent overloading the api\n",
    "while year < 2013:\n",
    "    scrapper = ScrapeBoxOffice(year=year, save=True, save_raw=True, output_dir='data')\n",
    "    df_box = scrapper.run()\n",
    "    movies_year = df_box[\"Release Group\"].tolist()\n",
    "    get_year_movie_data(movies_year, \"http://www.omdbapi.com/?t=\", str(year))\n",
    "    file_path_movie = \"MovieData\" + str(year) + \".json\"\n",
    "    df_movie_data = pd.read_json(file_path_movie)\n",
    "    box_df_bet = df_box.rename(columns={\"Release Group\": 'Title'})\n",
    "    master_df = pd.merge(df_movie_data, box_df_bet, on = \"Title\", how = \"inner\")\n",
    "    master_df[\"Year\"] = year\n",
    "    dataframe_1 = pd.concat([dataframe_1, master_df])\n",
    "    year = year + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394bb999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the second day\n",
    "year = 2013\n",
    "dataframe_2 = pd.DataFrame()\n",
    "while year < 2016:\n",
    "    scrapper = ScrapeBoxOffice(year=year, save=True, save_raw=True, output_dir='data')\n",
    "    df_box = scrapper.run()\n",
    "    movies_year = df_box[\"Release Group\"].tolist()\n",
    "    get_year_movie_data(movies_year, \"http://www.omdbapi.com/?t=\", str(year))\n",
    "    file_path_movie = \"MovieData\" + str(year) + \".json\"\n",
    "    df_movie_data = pd.read_json(file_path_movie)\n",
    "    box_df_bet = df_box.rename(columns={\"Release Group\": 'Title'})\n",
    "    master_df = pd.merge(df_movie_data, box_df_bet, on = \"Title\", how = \"inner\")\n",
    "    master_df[\"Year\"] = year\n",
    "    dataframe_2 = pd.concat([dataframe_2, master_df])\n",
    "    year = year + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d07980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the third day\n",
    "year = 2016\n",
    "dataframe_3 = pd.DataFrame()\n",
    "while year < 2020:\n",
    "    scrapper = ScrapeBoxOffice(year=year, save=True, save_raw=True, output_dir='data')\n",
    "    df_box = scrapper.run()\n",
    "    movies_year = df_box[\"Release Group\"].tolist()\n",
    "    get_year_movie_data(movies_year, \"http://www.omdbapi.com/?t=\", str(year))\n",
    "    file_path_movie = \"MovieData\" + str(year) + \".json\"\n",
    "    df_movie_data = pd.read_json(file_path_movie)\n",
    "    box_df_bet = df_box.rename(columns={\"Release Group\": 'Title'})\n",
    "    master_df = pd.merge(df_movie_data, box_df_bet, on = \"Title\", how = \"inner\")\n",
    "    master_df[\"Year\"] = year\n",
    "    dataframe_3 = pd.concat([dataframe_3, master_df])\n",
    "    year = year + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6e2997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the fourth day\n",
    "year = 2020\n",
    "dataframe_4 = pd.DataFrame()\n",
    "while year < 2023:\n",
    "    scrapper = ScrapeBoxOffice(year=year, save=True, save_raw=True, output_dir='data')\n",
    "    df_box = scrapper.run()\n",
    "    movies_year = df_box[\"Release Group\"].tolist()\n",
    "    get_year_movie_data(movies_year, \"http://www.omdbapi.com/?t=\", str(year))\n",
    "    file_path_movie = \"MovieData\" + str(year) + \".json\"\n",
    "    df_movie_data = pd.read_json(file_path_movie)\n",
    "    box_df_bet = df_box.rename(columns={\"Release Group\": 'Title'})\n",
    "    master_df = pd.merge(df_movie_data, box_df_bet, on = \"Title\", how = \"inner\")\n",
    "    master_df[\"Year\"] = year\n",
    "    dataframe_4 = pd.concat([dataframe_4, master_df])\n",
    "    year = year + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0eeea0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge all the dataframes\n",
    "dataframe = pd.concat([dataframe_1, dataframe_2, dataframe_3, dataframe_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb529a3-b064-4b6d-8ffc-05cbf2e0667b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning the data\n",
    "def clean_box_office(df):\n",
    "    '''Cleans box office sales by removing dollar signs and commas, and drops rows where Domestic value is \"-\".'''\n",
    "    # Clean Worldwide column\n",
    "    df = df[df[\"Domestic\"] != \"-\"]\n",
    "    df = df.dropna(subset = [\"Worldwide\", \"Domestic\", \"Foreign\"])\n",
    "    df[\"Worldwide\"] = (\n",
    "        df[\"Worldwide\"]\n",
    "        .astype(str)  \n",
    "        .str.replace(\"$\", \"\", regex=False)  \n",
    "        .str.replace(\",\", \"\", regex=False)  \n",
    "        .astype(int)\n",
    "    )\n",
    "    # Clean Domestic column\n",
    "    df[\"Domestic\"] = (\n",
    "        df[\"Domestic\"]\n",
    "        .astype(str)  \n",
    "        .str.replace(\"$\", \"\", regex=False) \n",
    "        .str.replace(\",\", \"\", regex=False)  \n",
    "    \n",
    "    )\n",
    "    # Clean Foreign column\n",
    "    df[\"Foreign\"] = (\n",
    "        df[\"Foreign\"]\n",
    "        .astype(str)  \n",
    "        .str.replace(\"$\", \"\", regex=False)  \n",
    "        .str.replace(\",\", \"\", regex=False)  \n",
    "    )\n",
    "    # Creating new columns because the raw numbers are too large to process\n",
    "    df[\"Worldwide_millions\"] = pd.to_numeric(df[\"Worldwide\"]) / 1000000\n",
    "    df[\"Domestic_millions\"] = pd.to_numeric(df[\"Domestic\"]) / 1000000\n",
    "    df[\"Foreign_millions\"] = pd.to_numeric(df[\"Foreign\"], errors=\"coerce\") / 1000000\n",
    "    return df\n",
    "\n",
    "#dataframe = dataframe.drop([\"Type\", \"Poster\", \"DVD\", \"totalSeasons\", \"Error\", \"Response\", \"Website\", \"Rank\", \"Production\"], axis=1)\n",
    "#cleaned_df = clean_box_office(dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81dcbcad-e4da-40c2-b17f-e716616c6c3b",
   "metadata": {},
   "source": [
    "## Part 3:\n",
    "(2\\%) Builds at least two visualizations (graphs/plots) from the data which help to understand or answer the questions of interest. These visualizations will be graded based on how much information they can effectively communicate to readers. Please make sure your visualization are sufficiently distinct from each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c7c2ed",
   "metadata": {},
   "source": [
    "The visualizations that we made for this part are:\n",
    "(1) Genre analysis histogram: for all movies in the time period, how many are there of each genre? Which genre is the most popular?\n",
    "(2) Time series analysis on box office revenue: how has total box office revenue fluctuated over the time period?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
